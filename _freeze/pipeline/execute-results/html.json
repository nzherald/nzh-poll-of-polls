{
  "hash": "8d1bece8ad2b0fa11f8a69dd840f0756",
  "result": {
    "markdown": "---\ntitle: \"Model pipeline\"\noutput: html_document\n---\n\n\n\n\n## Intro\n\nWe use the [{targets}](https://books.ropensci.org/targets/) package to manage\nthe code pipeline used for running the model.\n\nSee [setup](setup.qmd) for more info.\n\n## Globals\n\nWe first define some global options/functions common to all targets. The list of\npackages loaded below are what targets needs to run the pipeline - along with\nthe targets package itself and two additional targets-related\npackages: [tarchetypes](https://docs.ropensci.org/tarchetypes/index.html) and\n[stantargets](https://docs.ropensci.org/stantargets/index.html). If you don't \nwant to use renv then manually installing these should be sufficient.\n\n\n\n::: {.cell tar_globals='true'}\n\n```{.r .cell-code}\nlibrary(targets)\nlibrary(tarchetypes)\nlibrary(stantargets)\noptions(tidyverse.quiet = TRUE)\ntar_source() # grab all functions in R folder\ntar_option_set(packages = c(\n  \"readr\",\n  \"tidyr\",\n  \"rvest\",\n  \"glue\",\n  \"dplyr\",\n  \"stringr\",\n  \"lubridate\",\n  \"forcats\",\n  \"ggplot2\",\n  \"svglite\",\n  \"scales\",\n  \"janitor\",\n  \"ggthemes\",\n  \"nzelect\",\n  \"purrr\"\n))\n#> Establish _targets.R and _targets_r/globals/example-globals.R.\n```\n:::\n\n\n## Targets\n\nThe canonical location for NZ polling data appears to be Wikipedia pages.\nThe first part of this pipeline downloads the poll results from the Wikipedia pages.\nIt also fetches recent election results from the electoral commission.\n\nOnce the poll results have been downloaded they are filtered and marshalled into the\nformat need by the model. \n\nThe model is then run and a few charts are generated from the model results.\n\n### URLs\n\nTarchetypes has a useful [function `tar_url`](https://docs.ropensci.org/tarchetypes/reference/tar_formats.html)\nfor working with urls. When the pipeline is run it will check the `last-modified`\nheader with the remote site. If this has changed any targets that depend on the\nurl will be run again. Checking the URL is a little slow for regular development\nso [tar_cue_skip](https://docs.ropensci.org/tarchetypes/reference/tar_cue_skip.html)\ncan be used to skip the check - just set `skip_url_check` below to `TRUE`.\n\nNote that often this results in one of the poll objects being extracted again but\nno further dependencies are run as the resulting data has not changed. This ensures\nthat minor changes to the page do not trigger a model re-run. \n\nThe code to generate the urls is defined in [R/urls.R](https://github.com/nzherald/nzh-poll-of-polls/blob/main/R/urls.R)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskip_url_check <- FALSE\nlist(\n  tar_url(polls2011_url, wikipedia_poll_url(2011), cue = tar_cue_skip(skip_url_check)),\n  tar_url(polls2014_url, wikipedia_poll_url(2014), cue = tar_cue_skip(skip_url_check)),\n  tar_url(polls2017_url, wikipedia_poll_url(2017), cue = tar_cue_skip(skip_url_check)),\n  tar_url(polls2020_url, wikipedia_poll_url(2020), cue = tar_cue_skip(skip_url_check)),\n  tar_url(polls2023_url, wikipedia_poll_url(2023), cue = tar_cue_skip(skip_url_check)),\n  tar_url(results2008_url, election_results_summary(2008), cue = tar_cue_skip(skip_url_check)),\n  tar_url(results2011_url, election_results_summary(2011), cue = tar_cue_skip(skip_url_check)),\n  tar_url(results2014_url, election_results_summary(2014), cue = tar_cue_skip(skip_url_check)),\n  tar_url(results2017_url, election_results_summary(2017), cue = tar_cue_skip(skip_url_check)),\n  tar_url(results2020_url, election_results_summary(2020), cue = tar_cue_skip(skip_url_check))\n)\n#> Establish _targets.R and _targets_r/targets/urls.R.\n```\n:::\n\n\n\n### Download polls\n\nPolling for each election is extracted into it's own object. Then all the\nobjects are combined into a single consistent object.\n\nThe code that does the heavy lifting is in\n[R/read-polls.R](https://github.com/nzherald/nzh-poll-of-polls/blob/main/R/read-polls.R)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(polls2011, extract_poll_results_2011(polls2011_url)),\n  tar_target(polls2014, extract_poll_results_2014(polls2014_url)),\n  tar_target(polls2017, extract_poll_results_2017(polls2017_url)),\n  tar_target(polls2020, extract_poll_results_2020(polls2020_url)),\n  tar_target(polls2023, extract_poll_results_2023(polls2023_url)),\n  tar_target(polls, combine_polls(polls2011,polls2014,polls2017,polls2020,polls2023))\n)\n#> Establish _targets.R and _targets_r/targets/polls.R.\n```\n:::\n\n\nThe electoral commission produces usually formatted csv files - the code in \n[R/fetch-results.R](https://github.com/nzherald/nzh-poll-of-polls/blob/main/R/fetch-results.R)\nreads just a small portion of the results file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(results2020, fetch_results(results2020_url, 17, 2020)),\n  tar_target(results2017, fetch_results(results2017_url, 16, 2017)),\n  tar_target(results2014, fetch_results(results2014_url, 15, 2014)),\n  tar_target(results2011, fetch_results(results2011_url, 13, 2011)),\n  tar_target(results2008, fetch_results(results2008_url, 19, 2008)),\n  tar_target(\n    results,\n    combine_results(\n      results2008,\n      results2011,\n      results2014,\n      results2017,\n      results2020\n    )\n  )\n  \n)\n#> Establish _targets.R and _targets_r/targets/results.R.\n```\n:::\n\n\n### Selecting parties and pollsters\n\nOnly include pollsters who have provided a poll for the 2023 election and who\nuse the NZ Political Polling Code.\n\nInclude parties who currently have a seat in parliament or who have polled over\n2.5% three times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(pollsters, polls |> \n               filter(Election == 2023) |> \n               distinct(Pollster) |> \n               filter(!grepl('Roy|Horizon', Pollster))),\n  tar_target(parties_in_parliament, \n             tibble(Party = c('ACT', 'Green', 'Labour', 'National', 'Te Pāti Māori'))),\n  tar_target(parties,  polls |> \n               filter(Election == 2023, VotingIntention > 0.025) |>\n               filter(n() > 3, .by=Party) |> \n               distinct(Party) |> \n               union(parties_in_parliament) |> \n               arrange(Party)),\n  tar_target(pollsters2020, polls |> \n               filter(Election == 2020,\n                      Pollster != 'YouGov') |> # Only one YouGov poll \n               distinct(Pollster)),\n  tar_target(parties_in_parliament2020, \n             tibble(Party = c('ACT', 'Green', 'Labour', 'National', 'NZ First'))),\n  tar_target(parties2020,  polls |> \n               filter(Election == 2020, VotingIntention > 0.025) |>\n               filter(n() > 3, .by=Party) |> \n               distinct(Party) |> \n               union(parties_in_parliament2020) |> \n               arrange(Party)),\n  tar_target(party_colours,\n             tribble(\n               ~Party, ~Colour,\n               \"ACT\", \"#ffd100\",\n               \"Green\", \"#00491E\",\n               \"Labour\", \"#d82c20\",\n               \"Te Pāti Māori\", \"#D12C38\",\n               \"National\", \"#065BAA\",\n               \"NZ First\", \"#212529\",\n               \"TOP\", \"#09B598\",\n               \"Other\", \"#B3B3B3\"\n             ) |> mutate(Party = as_factor(Party)))\n)\n#> Establish _targets.R and _targets_r/targets/params.R.\n```\n:::\n\n\n### Marshal the data\n\nThis code is very similar to Peter Ellis' code for marshalling polls and results\ninto a object for stan.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(election_dates, ymd(c(\"2014-09-20\", \"2017-09-23\", \"2020-10-17\", \"2023-10-14\"))),\n  tar_target(election_weeks, floor_date(election_dates, unit = 'week')),\n  tar_target(weeks_between_elections, as.integer(diff(election_weeks)) / 7),\n  tar_target(\n    elections,\n    results |>\n      filter(Election >= year(min(election_weeks))) |>\n      mutate(\n        Party = fct_other(Party, keep = parties$Party) |>\n          fct_relevel(parties$Party)\n      ) |>\n      count(Party, Election, wt = Percentage, name = 'Percentage') |>\n      arrange(Party, Election) |>\n      pivot_wider(names_from = Party, values_from = Percentage, values_fill = 0) |>\n      select(-Election)\n  ),\n  tar_target(\n    polls2,\n    polls |>\n  filter(Pollster %in% c(pollsters$Pollster), !is.na(MidPoint)) |>\n  mutate(\n    MidPoint = floor_date(MidPoint, unit = 'week'),\n    Party = fct_other(Party, keep = parties$Party) |>\n      fct_relevel(parties$Party)\n  ) |>\n  filter(Party != 'Other') |> \n  mutate(Polled = sum(VotingIntention), .by = c(Pollster, MidPoint)) |> \n  rename(MidDate = MidPoint, ElectionYear = Election) |>\n  select(\n    `Date range`,\n    Party,\n    Pollster,\n    MidDate,\n    ElectionYear,\n    Polled,\n    VotingIntention\n  ) |>\n  filter(ElectionYear %in% year(election_weeks[-1])) |>\n  arrange(Party, MidDate) |>\n  pivot_wider(\n    names_from = Party,\n    values_from = VotingIntention,\n    names_sort = TRUE,\n    values_fill = 0\n  ) |>\n  mutate(Other = pmax(0, 1 - Polled),\n         MidDateNumber = 1 + as.numeric(MidDate - election_weeks[1]) / 7) |> \n  select(-Polled, -`Date range`)\n),\n  tar_target(\n    polls3,\n    polls2 |>\n      arrange(Pollster, MidDate) |>\n      group_split(Pollster)\n  ),\n  tar_target(parties_ss, names(elections)),\n  tar_target(\n    # estimate the standard errors.  Note we are pretending they all have a sample size of 1000 -\n    # which the main five do, but not some of the smaller ones.  Improvement would be to better deal with this.\n    \n    all_ses,\n    polls2 |>\n      select(Pollster, ACT:Other) |>\n      pivot_longer(ACT:Other, names_to = 'Party', values_to = 'p') |>\n      summarise(\n        p = mean(p, na.rm = T),\n        se = sqrt(p * (1 - p) / 1000),\n        .by = c(Pollster, Party)\n      )\n  ),\n  tar_target(\n    ses3,\n    all_ses |>\n      arrange(Pollster, Party) |>\n      group_split(Pollster)\n  ),\n  tar_target(\n    d1, list(mu_elect1 = as.numeric(elections[1, ]), \n           mu_elect2 = as.numeric(elections[2, ]),\n           mu_elect3 = as.numeric(elections[3, ]), \n\n           n_parties = length(parties_ss),\n           n_weeks = weeks_between_elections, \n           # multiply the variance of all polls by 2.  See my blog post of 9 July 2017.\n           inflator = sqrt(2),\n           \n           y1_n = nrow(polls3[[1]]),\n           y1_values = polls3[[1]][ , 4:11],\n           y1_weeks = as.numeric(polls3[[1]]$MidDateNumber),\n           y1_se = ses3[[1]]$se,\n           \n           y2_n = nrow(polls3[[2]]),\n           y2_values = polls3[[2]][ , 4:11],\n           y2_weeks = as.numeric(polls3[[2]]$MidDateNumber),\n           y2_se = ses3[[2]]$se,\n           \n           y3_n = nrow(polls3[[3]]),\n           y3_values = polls3[[3]][ , 4:11],\n           y3_weeks = as.numeric(polls3[[3]]$MidDateNumber),\n           y3_se = ses3[[3]]$se,\n           \n           y4_n = nrow(polls3[[4]]),\n           y4_values = polls3[[4]][ , 4:11],\n           y4_weeks = as.numeric(polls3[[4]]$MidDateNumber),\n           y4_se = ses3[[4]]$se,\n           reid_method = as.numeric(polls3[[4]]$MidDate >= as.Date(\"2017-01-01\")),\n           \n           n_pollsters = 4)\n  )\n)\n\n#> Establish _targets.R and _targets_r/targets/prep.R.\n```\n:::\n\n\n### 2020 version of the model\n\nThis is a bit of a nasty copy-paste from above - it runs a version of the model\nfor the 2020 election that we can use to check how well the model performs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(election_weeks2020, floor_date(ymd(\n    c(\"2011-11-26\", \"2014-09-20\", \"2017-09-23\", \"2020-10-17\")\n  ), unit = 'week')),\n  tar_target(weeks_between_elections2020, as.integer(diff(election_weeks)) / 7),\n  tar_target(\n    elections2020,\n    results |>\n      filter(Election >= year(min(election_weeks2020)) & \n               Election < year(max(election_weeks2020))) |>\n      mutate(\n        Party = fct_other(Party, keep = parties2020$Party) |>\n          fct_relevel(parties2020$Party)\n      ) |>\n      count(Party, Election, wt = Percentage, name = 'Percentage') |>\n      arrange(Party, Election) |>\n      pivot_wider(names_from = Party, values_from = Percentage, values_fill = 0) |>\n      select(-Election)\n  ),\n  tar_target(\n    polls22020,\n    polls |>\n      filter(Election %in% c(2014, 2017, 2020),\n             Pollster %in% c(pollsters2020$Pollster),\n             !is.na(MidPoint)) |>\n  mutate(\n    MidPoint = floor_date(MidPoint, unit = 'week'),\n    Party = fct_other(Party, keep = parties2020$Party) |>\n      fct_relevel(parties2020$Party)\n  ) |>\n  filter(Party != 'Other') |> \n  mutate(Polled = sum(VotingIntention), .by = c(Pollster, MidPoint)) |> \n  rename(MidDate = MidPoint, ElectionYear = Election) |>\n  count(\n    Party,\n    Pollster,\n    MidDate,\n    ElectionYear,\n    Polled,\n    wt = VotingIntention,\n    name = \"VotingIntention\"\n  ) |>\n  filter(MidDate <= election_weeks2020[4]) |>\n  arrange(Party, MidDate) |>\n  pivot_wider(\n    names_from = Party,\n    values_from = VotingIntention,\n    names_sort = TRUE,\n    values_fill = 0\n  ) |>\n  mutate(Other = pmax(0, 1 - Polled),\n         MidDateNumber = 1 + as.numeric(MidDate - election_weeks2020[1]) / 7) |> \n  select(-Polled)\n\n  ),\n  tar_target(\n    polls32020,\n    polls22020 |>\n      arrange(Pollster, MidDate) |>\n      group_split(Pollster)\n  ),\n  tar_target(parties_ss2020, names(elections2020)),\n  tar_target(\n    # estimate the standard errors.  Note we are pretending they all have a sample size of 1000 -\n    # which the main five do, but not some of the smaller ones.  Improvement would be to better deal with this.\n    \n    all_ses2020,\n    polls22020 |>\n      select(Pollster, ACT:Other) |>\n      pivot_longer(ACT:Other, names_to = 'Party', values_to = 'p') |>\n      summarise(\n        p = mean(p, na.rm = T),\n        se = sqrt(p * (1 - p) / 1000),\n        .by = c(Pollster, Party)\n      )\n  ),\n  tar_target(\n    ses32020,\n    all_ses2020 |>\n      arrange(Pollster, Party) |>\n      group_split(Pollster)\n  ),\n  tar_target(\n    d12020, list(mu_elect1 = as.numeric(elections2020[1, ]), \n           mu_elect2 = as.numeric(elections2020[2, ]),\n           mu_elect3 = as.numeric(elections2020[3, ]), \n\n           n_parties = length(parties_ss2020),\n           n_weeks = weeks_between_elections2020, \n           # multiply the variance of all polls by 2.  See my blog post of 9 July 2017.\n           inflator = sqrt(2),\n           \n           y1_n = nrow(polls32020[[1]]),\n           y1_values = polls32020[[1]][ , 4:9],\n           y1_weeks = as.numeric(polls32020[[1]]$MidDateNumber),\n           y1_se = ses32020[[1]]$se,\n           \n           y2_n = nrow(polls32020[[2]]),\n           y2_values = polls32020[[2]][ , 4:9],\n           y2_weeks = as.numeric(polls32020[[2]]$MidDateNumber),\n           y2_se = ses32020[[2]]$se,\n           reid_method = as.numeric(polls32020[[2]]$MidDate >= as.Date(\"2017-01-01\")),\n           \n           y3_n = nrow(polls32020[[3]]),\n           y3_values = polls32020[[3]][ , 4:9],\n           y3_weeks = as.numeric(polls32020[[3]]$MidDateNumber),\n           y3_se = ses32020[[3]]$se,\n           \n           n_pollsters = 3)\n  )\n)\n\n#> Establish _targets.R and _targets_r/targets/prep2020.R.\n```\n:::\n\n\n### Run the models\n\nUses `stantargets` to run the model - see\n[tar_stan_mcmc](https://docs.ropensci.org/stantargets/reference/tar_stan_mcmc.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_stan_mcmc(\n    model2023,\n    \"stan/model2023.stan\",\n    dir = \".stan\",\n    data = d1,\n    chains = 4,\n    parallel_chains = 4,\n    iter_sampling = 2000,\n    max_treedepth = 20,\n    deployment = \"worker\"\n  ),\n    tar_stan_mcmc(\n    model2020,\n    \"stan/model2020.stan\",\n    dir = \".stan\",\n    data = d12020,\n    chains = 4,\n    parallel_chains = 4,\n    iter_sampling = 2000,\n    max_treedepth = 20,\n    deployment = \"worker\"\n  )\n\n)\n#> Establish _targets.R and _targets_r/targets/modelling.R.\n```\n:::\n\n\n### Charts\n\n#### Voting intention\n\nCurrent charts are more or less the same as some of Peter's charts. Future\nversions will export the data to create more interactive charts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(\n    voting_intention_chartdata,\n    model2023_summary_model2023 |>\n      filter(str_starts(variable, \"mu\")) |>\n      mutate(\n        Party = rep(parties_ss, each = sum(weeks_between_elections)),\n        week = rep(1:sum(weeks_between_elections), length(parties_ss)),\n        week = min(election_weeks) + weeks(week)\n      )\n  ),\n  tar_target(\n    voting_intention_chart,\n    voting_intention_chartdata |>\n      ggplot(aes(\n        x = week,\n        y = mean,\n        colour = Party,\n        fill = Party\n      )) +\n      geom_point(\n        data = gather(\n          polls2,\n          Party,\n          VotingIntention,-Pollster,-MidDate,-ElectionYear,-MidDateNumber\n        ) |>\n          filter(VotingIntention != 0),\n        aes(x = MidDate, y = VotingIntention),\n        colour = \"black\",\n        size = 0.5\n      ) +\n      geom_vline(\n        xintercept = as.numeric(election_dates),\n        colour = \"grey60\"\n      ) +\n      scale_y_continuous(labels = percent) +\n      scale_x_date(breaks = ym(\n        c('2016-01', '2018-01', '2020-01', '2022-01')\n      ), date_labels = '%Y') +\n      scale_fill_manual(values = party_colours$Colour, breaks = party_colours$Party) +\n      geom_line(\n        data = voting_intention_chartdata |> filter(week <= today()),\n        colour = \"black\"\n      ) +\n      geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.3, colour = NA) +\n      labs(y = NULL, x = NULL) +\n      theme_clean() +\n      theme(\n        plot.title.position = \"plot\",\n        legend.position = 'none',\n        strip.background = element_rect(fill = '#121617'),\n        strip.text = element_text(colour = 'white'),\n        plot.background = element_blank()\n      )\n  ),\n  tar_file(voting_intention620, {\n    f <- \"output/voting_intention620.svg\"\n    ggsave(\n      f,\n      plot = voting_intention_chart +\n        facet_wrap(\n          ~ factor(Party, levels = party_colours$Party),\n          scales = \"free\",\n          ncol = 2\n        ),\n      dpi = 100,\n      width = 6.2,\n      height = 8\n    )\n    f\n  }),\n  tar_file(voting_intention375, {\n    f <- \"output/voting_intention375.svg\"\n    ggsave(\n      f,\n      plot = voting_intention_chart +\n        facet_wrap(\n          ~ factor(Party, levels = party_colours$Party),\n          scales = \"free\",\n          ncol = 1\n        ),\n      dpi = 100,\n      width = 3.75,\n      height = 10\n    )\n    f\n  })\n)\n#> Establish _targets.R and _targets_r/targets/charts.R.\n```\n:::\n\n\n#### Possible coaltion plots\n\nGrab the simulation results for party vote for election night and the current\nweek. Currently hard coding the current week - but will need to do something better.\n\nAssumption is hard-coded that parties that currently have an electorate seat will\nkeep at least one and no additional parties will pick up an electorate seat. \nFuture work will make this more flexible.\n\nWe render an mobile screen sized plot and the desktop sized plot and load these \nas SVGs - slightly clunky but is actually a good way to display ggplot2 images\non the web.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_seats <- function(sims) {\n  t(sapply(1:nrow(sims), function(i) {\n    allocate_seats(\n      votes = as.numeric(sims[i,]),\n      electorate = c(1, 1, 1, 1, 0, 1, 0),\n      parties = names(sims)\n    )$seats_v\n  })) |>\n    as_tibble() |>\n    mutate(\n      NatCoal = ACT + National,\n      LabGreen = Labour + Green,\n      LabGreenMaori = Labour + Green + `Te Pāti Māori`,\n      NatCoalMaori = NatCoal + `Te Pāti Māori`\n    )\n}\n\nlist(\n  tar_target(\n    weekly_mu,\n    model2023_mcmc_model2023$draws('mu', format = 'draws_matrix')\n  ),\n  tar_target(\n    sims_election_night,\n    weekly_mu[, 1:8 * 473] |> as_tibble() |> set_names(parties_ss) |>\n      select(all_of(sort(parties_ss))) |>\n      select(-Other) \n  ),\n  tar_target(\n    sims_saturday,\n    weekly_mu[, 1:8 * 473 - 24] |> as_tibble() |> set_names(parties_ss) |>\n      select(all_of(sort(parties_ss))) |>\n      select(-Other) \n  ),\n  tar_target(seats_election_night, simulate_seats(sims_election_night)),\n  tar_target(seats_saturday, simulate_seats(sims_saturday))\n)\n#> Establish _targets.R and _targets_r/targets/seats.R.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoalition_plot <- function(seats) {\n  seats  |>\n    select(National,\n           Labour,\n           NatCoal,\n           LabGreen,\n           LabGreenMaori,\n           NatCoalMaori) |>\n    gather(Coalition, Seats) |>\n    mutate(lab_in = ifelse(grepl(\"^Lab\", Coalition), \"Labour-based\", \"Nationals-based\")) |>\n    mutate(\n      Coalition = gsub(\"^LabGreen\", \"Labour, Greens\", Coalition),\n      Coalition = gsub(\"^NatCoal\", \"National, ACT\", Coalition),\n      Coalition = gsub(\"Maori\", \",\\nTe Pāti Māori\", Coalition)\n    ) |>\n    ggplot(aes(x = Seats, fill = lab_in)) +\n    geom_histogram(\n      alpha = 0.5,\n      binwidth = 1,\n      position = \"identity\",\n      colour = NA\n    )  +\n    scale_y_continuous() +\n    scale_fill_manual(values = c('#d82c20', '#065BAA')) +\n    theme_clean() +\n    theme(\n      legend.position = 'none',\n      strip.background = element_rect(fill = '#121617'),\n      strip.text = element_text(colour = 'white'),\n      plot.background = element_blank()\n    ) +\n    labs(y = NULL) +\n    annotate(\n      'segment',\n      x = 61,\n      xend = 61,\n      y = 0,\n      yend = Inf\n    )\n}\n\nlist(\n  tar_target(election_night_plot, coalition_plot(seats_election_night)),\n  tar_target(saturday_plot, coalition_plot(seats_saturday)),\n  tar_file(election_night620, {\n    f <- \"output/election_night620.svg\"\n    ggsave(\n      f,\n      plot = election_night_plot +\n        facet_wrap(~ factor(\n          Coalition,\n          levels = c(\n            \"Labour\",\n            \"National\",\n            \"Labour, Greens\",\n            \"National, ACT\",\n            \"Labour, Greens,\\nTe Pāti Māori\",\n            \"National, ACT,\\nTe Pāti Māori\"\n          )\n        ), ncol = 2),\n      dpi = 100,\n      width = 6.2,\n      height = 4\n    )\n    f\n  }),\n  tar_file(election_night375, {\n    f <- \"output/election_night375.svg\"\n    ggsave(\n      f,\n      plot = election_night_plot +\n        facet_wrap(~ Coalition,\n                   ncol = 1),\n      dpi = 100,\n      width = 3.75,\n      height = 7\n    )\n    f\n  }),\n  tar_file(saturday620, {\n    f <- \"output/saturday620.svg\"\n    ggsave(\n      f,\n      plot = saturday_plot +\n        facet_wrap(~ factor(\n          Coalition,\n          levels = c(\n            \"Labour\",\n            \"National\",\n            \"Labour, Greens\",\n            \"National, ACT\",\n            \"Labour, Greens,\\nTe Pāti Māori\",\n            \"National, ACT,\\nTe Pāti Māori\"\n          )\n        ), ncol = 2),\n      dpi = 100,\n      width = 6.2,\n      height = 4\n    )\n    f\n  }),\n  tar_file(saturday375, {\n    f <- \"output/saturday375.svg\"\n    ggsave(\n      f,\n      plot = saturday_plot +\n        facet_wrap(~ Coalition,\n                   ncol = 1),\n      dpi = 100,\n      width = 3.75,\n      height = 7\n    )\n    f\n  })\n)\n#> Establish _targets.R and _targets_r/targets/coalition-plot.R.\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}